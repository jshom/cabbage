{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all the packages\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all the layer types that we gonna need\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_text_filename = \"paul_graham.txt\"\n",
    "training_raw_text = open(\n",
    "    training_text_filename,\n",
    "    'r',\n",
    "    encoding='utf-8')\\\n",
    "    .read()\\\n",
    "    .lower()\\\n",
    "    .replace(\"\\r\",\" \")\\\n",
    "    .replace(\"\\n\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'there are two distinct ways to be politically moderate: on purpose and by accident. intentional moderates are trimmers, deliberately choosing a position mid-way between the extremes of right and left. accidental moderates end up in the middle, on average, because they make up their own minds about e'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the data was actually read correctly\n",
    "training_raw_text[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(training_raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_raw_text_length: 132013\n",
      "training_unique_characters_count: 61\n"
     ]
    }
   ],
   "source": [
    "training_raw_text_length = len(training_raw_text)\n",
    "training_unique_characters_count = len(chars)\n",
    "print(\"training_raw_text_length:\", training_raw_text_length)\n",
    "print(\"training_unique_characters_count:\", training_unique_characters_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the lenght of the char input arr.\n",
    "# Example: if input seq length was 3, take for instance input \"fuc\", my best guess for next char is \"k\".\n",
    "input_sequence_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the input dataset\n",
    "# Example: if input seq length is 3\n",
    "# For text a b c d e f g\n",
    "# gen targets: -> [abc] => d, [bcd] => e, [cde] => f and so on ...\n",
    "# inputs = [abc, bcd, cde]; targets = [d,e,f]\n",
    "# We can call the set of inputs and targets as patterns\n",
    "inputs = []\n",
    "targets = []\n",
    "for i in range(0, training_raw_text_length - input_sequence_length, 1):\n",
    "    sequence_input = training_raw_text[i:i + input_sequence_length]\n",
    "    target = training_raw_text[i + input_sequence_length]\n",
    "    inputs.append([char_to_int[char] for char in sequence_input])\n",
    "    targets.append(char_to_int[target])\n",
    "pattern_count = len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE\n",
      "in: [51, 39, 36, 49, 36, 0, 32, 49, 36, 0, 51, 54, 46, 0, 35, 40, 50, 51, 40, 45] out 34\n"
     ]
    }
   ],
   "source": [
    "# see first input and output\n",
    "print(\"EXAMPLE\")\n",
    "print(\"in:\", inputs[0], \"out\", targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# FUN TIME - FORMAT DATA FOR MODEL\n",
    "# --------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsure what 1 is, it says [samples, timesteps, features] in the article,\n",
    "# I guess each character is one feature, if image data this could probs be many? idk?\n",
    "# Dividing by the end with /triaining_unique_characters_count maps inputs to 0-1 range\n",
    "ready_input_data = np.reshape(inputs, (pattern_count, input_sequence_length, 1)) / training_unique_characters_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83606557],\n",
       "       [0.63934426],\n",
       "       [0.59016393],\n",
       "       [0.80327869],\n",
       "       [0.59016393],\n",
       "       [0.        ],\n",
       "       [0.52459016],\n",
       "       [0.80327869],\n",
       "       [0.59016393],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example prepared input, only showing first 10 of the 100 with [:10]\n",
    "ready_input_data[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_target_data = to_categorical(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131993, 20, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examlpe of ready target data, one hot encoding so of the [0...training_unique_characters_count]\n",
    "# the character is marked as a one where the rest are zeros\n",
    "print(ready_input_data.shape)\n",
    "ready_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# REAL FUN TIME - DEFINE MODEL AAAAND SEEEND IT\n",
    "# ----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_model = Sequential([\n",
    "    LSTM(256, input_shape=(ready_input_data.shape[1], ready_input_data.shape[2])),\n",
    "    Dropout(0.05),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(ready_target_data.shape[1], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for training\n",
    "text_generation_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam')\n",
    "# load weights if they exist\n",
    "if os.path.isfile('text-gen-weights.h5'):\n",
    "    text_generation_model.load_weights('text-gen-weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('text-gen-weights.h5'):\n",
    "    text_generation_model.fit(\n",
    "        ready_input_data,\n",
    "        ready_target_data,\n",
    "        epochs=2,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        validation_split=0.1,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_model.save_weights('text-gen-weights.h5')  # load weights with model.load_weights(filename)\n",
    "text_generation_model.save('text-gen-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# EVEN MORE REAL FUN TIME - GEN TEXT!!!\n",
    "# ----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id = np.random.randint(0, len(inputs) - 1)\n",
    "seed = inputs[input_id]\n",
    "input_char_indices = seed\n",
    "complete_string = ''.join([chars[val] for val in seed])\n",
    "\n",
    "print(complete_string)\n",
    "for i in range(200):\n",
    "    input_sequence = np.reshape(\n",
    "        input_char_indices,\n",
    "        (1, input_sequence_length, 1)\n",
    "    ) / training_unique_characters_count\n",
    "    # print(\"input_sequence\", input_sequence)\n",
    "    output_vector = text_generation_model.predict(input_sequence)    \n",
    "    next_char_index = np.argmax(output_vector)\n",
    "    next_char = chars[next_char_index]\n",
    "    #print(\"next_char_index\", next_char_index, \"next_char\", next_char)\n",
    "    # append to indices and readable string\n",
    "    print(\".\", ending='')\n",
    "    input_char_indices.append(next_char_index)\n",
    "    input_char_indices = input_char_indices[1:input_sequence_length+1]\n",
    "    complete_string = complete_string + next_char\n",
    "print(complete_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
