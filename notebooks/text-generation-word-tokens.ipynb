{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all the packages\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all the layer types that we gonna need\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_text_filename = \"paul_graham.txt\"\n",
    "training_raw_text = open(\n",
    "    training_text_filename,\n",
    "    'r',\n",
    "    encoding='utf-8')\\\n",
    "    .read()\\\n",
    "    .lower()\\\n",
    "    .replace(\"\\r\",\" \")\\\n",
    "    .replace(\"\\n\",\" \")\\\n",
    "    .replace(\"\\t\",\" \")\\\n",
    "    .replace(\"\\\"\", \"\")\\\n",
    "    .replace(\"\\'\", \"\")\\\n",
    "    .replace(\"(\", \"\")\\\n",
    "    .replace(\")\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the data was actually read correctly\n",
    "training_raw_text = training_raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create word tokens and mappings from token_id to token and token to token_id\n",
    "tokens = sorted(list(set(training_raw_text.split(' '))))\n",
    "token_to_id = dict((token, token_id) for token_id, token in enumerate(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23541\n"
     ]
    }
   ],
   "source": [
    "def tokenize_string(a_string: str) -> List[str]:\n",
    "    return a_string\\\n",
    "        .lower()\\\n",
    "        .replace(\"\\r\",\" \")\\\n",
    "        .replace(\"\\n\",\" \")\\\n",
    "        .replace(\"\\t\",\" \")\\\n",
    "        .replace(\"\\\"\", \"\")\\\n",
    "        .replace(\"\\'\", \"\")\\\n",
    "        .replace(\"(\", \"\")\\\n",
    "        .replace(\")\", \"\")\\\n",
    "        .split(' ')\n",
    "\n",
    "training_tokens = tokenize_string(training_raw_text)\n",
    "#print(training_tokens)\n",
    "training_token_ids = [token_to_id[token] for token in training_tokens]\n",
    "#print(\"smol example:\", training_token_ids[:5])\n",
    "print(len(training_token_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_length: 23541\n",
      "training_unique_characters_count: 3977\n"
     ]
    }
   ],
   "source": [
    "training_length = len(training_token_ids)\n",
    "unique_tokens = len(tokens)\n",
    "print(\"training_length:\", training_length)\n",
    "print(\"training_unique_characters_count:\", unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the lenght of the past words to take as input\n",
    "input_sequence_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23521"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the input dataset\n",
    "# Example: if input seq length is 3\n",
    "# For text a b c d e f g\n",
    "# gen targets: -> [abc] => d, [bcd] => e, [cde] => f and so on ...\n",
    "# inputs = [abc, bcd, cde]; targets = [d,e,f]\n",
    "# We can call the set of inputs and targets as patterns\n",
    "inputs = []\n",
    "targets = []\n",
    "for i in range(0, training_length - input_sequence_length, 1):\n",
    "    sequence_input = training_tokens[i:i + input_sequence_length]\n",
    "    target = training_tokens[i + input_sequence_length]\n",
    "    inputs.append([token_to_id[token] for token in sequence_input])\n",
    "    targets.append(token_to_id[target])\n",
    "pattern_count = len(inputs)\n",
    "pattern_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE\n",
      "in: [3496, 288, 3646, 1026, 3817, 3565, 387, 2611, 2210, 2401, 2749, 242, 509, 137, 1822, 2211, 288, 3616, 931, 600] out 113\n"
     ]
    }
   ],
   "source": [
    "# see first input and output\n",
    "print(\"EXAMPLE\")\n",
    "print(\"in:\", inputs[0], \"out\", targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# FUN TIME - FORMAT DATA FOR MODEL\n",
    "# --------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsure what 1 is, it says [samples, timesteps, features] in the article,\n",
    "# I guess each character is one feature, if image data this could probs be many? idk?\n",
    "# Dividing by the end with /triaining_unique_characters_count maps inputs to 0-1 range\n",
    "ready_input_data = np.reshape(inputs, (pattern_count, input_sequence_length, 1)) / len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87905456],\n",
       "       [0.07241639],\n",
       "       [0.91677144],\n",
       "       [0.2579834 ],\n",
       "       [0.95976867],\n",
       "       [0.89640432],\n",
       "       [0.09730953],\n",
       "       [0.65652502],\n",
       "       [0.55569525],\n",
       "       [0.6037214 ]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example prepared input, only showing first 10 of the 100 with [:10]\n",
    "ready_input_data[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_target_data = to_categorical(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23521, 20, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examlpe of ready target data, one hot encoding so of the [0...training_unique_characters_count]\n",
    "# the character is marked as a one where the rest are zeros\n",
    "print(ready_input_data.shape)\n",
    "ready_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# REAL FUN TIME - DEFINE MODEL AAAAND SEEEND IT\n",
    "# ----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_model = Sequential([\n",
    "    LSTM(64, input_shape=(ready_input_data.shape[1], ready_input_data.shape[2])),\n",
    "    Dropout(0.20),\n",
    "    Dense(256, activation='linear'),\n",
    "    Dense(32, activation='linear'),\n",
    "    Dense(ready_target_data.shape[1], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for training\n",
    "text_generation_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam')\n",
    "# load weights if they exist\n",
    "# if os.path.isfile('text-gen-words-weights.h5'):\n",
    "#     text_generation_model.load_weights('text-gen-words-weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "662/662 [==============================] - 17s 22ms/step - loss: 6.9910 - val_loss: 6.8183\n",
      "Epoch 2/10\n",
      "662/662 [==============================] - 14s 21ms/step - loss: 6.4685 - val_loss: 6.9099\n",
      "Epoch 3/10\n",
      "662/662 [==============================] - 15s 22ms/step - loss: 6.4363 - val_loss: 7.0017\n",
      "Epoch 4/10\n",
      "662/662 [==============================] - 15s 22ms/step - loss: 6.4318 - val_loss: 7.0678\n",
      "Epoch 5/10\n",
      "662/662 [==============================] - 15s 22ms/step - loss: 6.3814 - val_loss: 7.0939\n",
      "Epoch 6/10\n",
      "662/662 [==============================] - 16s 24ms/step - loss: 6.3079 - val_loss: 7.0982\n",
      "Epoch 7/10\n",
      "662/662 [==============================] - 15s 23ms/step - loss: 6.2883 - val_loss: 7.1647\n",
      "Epoch 8/10\n",
      "662/662 [==============================] - 15s 22ms/step - loss: 6.2767 - val_loss: 7.2351\n",
      "Epoch 9/10\n",
      "662/662 [==============================] - 15s 22ms/step - loss: 6.2453 - val_loss: 7.2525\n",
      "Epoch 10/10\n",
      "662/662 [==============================] - 13s 20ms/step - loss: 6.2420 - val_loss: 7.3103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0c098c1ef0>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if not os.path.isfile('text-gen-words-weights.h5'):\n",
    "    text_generation_model.fit(\n",
    "        ready_input_data,\n",
    "        ready_target_data,\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        validation_split=0.1,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_model.save_weights('text-gen-words-weights.h5')  # load weights with model.load_weights(filename)\n",
    "text_generation_model.save('text-gen-words-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# EVEN MORE REAL FUN TIME - GEN TEXT!!!\n",
    "# ----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: get the first commitment.  the biggest factor in most investors opinions of you is the opinion of other investors.\n",
      "GENERATION: get the first commitment.  the biggest factor in most investors opinions of you is the opinion of other investors. to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to\n"
     ]
    }
   ],
   "source": [
    "input_id = np.random.randint(0, len(inputs) - 1)\n",
    "seed = inputs[input_id]\n",
    "input_token_ids = seed\n",
    "complete_string = ' '.join([tokens[val] for val in seed])\n",
    "complete_string\n",
    "print(\"SEED:\", complete_string)\n",
    "for i in range(100):\n",
    "    input_sequence = np.reshape(\n",
    "        input_token_ids,\n",
    "        (1, input_sequence_length, 1)\n",
    "    ) / len(tokens)\n",
    "    #print(\"input_sequence\", input_sequence)\n",
    "    output_vector = text_generation_model.predict(input_sequence)    \n",
    "    next_token_id = np.argmax(output_vector)\n",
    "    next_token = tokens[next_token_id]\n",
    "    #print(\"next_token_id\", next_token_id, \"next_token\", next_token)\n",
    "    # append to indices and readable string\n",
    "    #print(\".\", ending='')\n",
    "    input_token_ids.append(next_token_id)\n",
    "    #print(len(input_token_ids))\n",
    "    input_token_ids = input_token_ids[1:]\n",
    "    #print(len(input_token_ids))\n",
    "    complete_string = complete_string + \" \" + next_token\n",
    "print(\"GENERATION:\", complete_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
